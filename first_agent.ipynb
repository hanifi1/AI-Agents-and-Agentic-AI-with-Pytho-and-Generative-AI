{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7a97159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Automatically looks for \".env\"\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# def generate_response(messages: List[Dict]) -> str:\n",
    "#     \"\"\"Call LLM to get response\"\"\"\n",
    "#     response = completion(\n",
    "#         model=\"openai/gpt-4o\",\n",
    "#         api_key= api_key,\n",
    "#         messages=messages,\n",
    "#         max_tokens=1024\n",
    "#     )\n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7900ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
    "    \"\"\"Extract code block from response\"\"\"\n",
    "\n",
    "    if not '```' in response:\n",
    "        return response\n",
    "\n",
    "    code_block = response.split('```')[1].strip()\n",
    "\n",
    "    if code_block.startswith(block_type):\n",
    "        code_block = code_block[len(block_type):].strip()\n",
    "\n",
    "    return code_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116b6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get a response.\"\"\"\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a340cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_action(response: str) -> Dict:\n",
    "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
    "    try:\n",
    "        response = extract_markdown_block(response, \"action\")\n",
    "        response_json = json.loads(response)\n",
    "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
    "            return response_json\n",
    "        else:\n",
    "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
    "\n",
    "def list_files() -> List[str]:\n",
    "    \"\"\"List files in the current directory.\"\"\"\n",
    "    return os.listdir(\".\")\n",
    "\n",
    "def read_file(file_name: str) -> str:\n",
    "    \"\"\"Read a file's contents.\"\"\"\n",
    "    try:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: {file_name} not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732586e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system instructions (Agent Rules)\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are an AI agent that can perform tasks by using available tools.\n",
    "\n",
    "Available tools:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"list_files\": {\n",
    "        \"description\": \"Lists all files in the current directory.\",\n",
    "        \"parameters\": {}\n",
    "    },\n",
    "    \"read_file\": {\n",
    "        \"description\": \"Reads the content of a file.\",\n",
    "        \"parameters\": {\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the file to read.\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"terminate\": {\n",
    "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
    "        \"parameters\": {\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Summary message to return to the user.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "If a user asks about files, documents, or content, first list the files before reading them.\n",
    "\n",
    "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
    "\n",
    "Important!!! Every response MUST have an action.\n",
    "You must ALWAYS respond in this format:\n",
    "\n",
    "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
    "\n",
    "```action\n",
    "{\n",
    "    \"tool_name\": \"insert tool_name\",\n",
    "    \"args\": {...fill in any required arguments here...}\n",
    "}\n",
    "```\"\"\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de0c5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent thinking...\n",
      "Agent response: <To determine what files are in the current directory, I need to list all the files first. This will help me understand what content is available before proceeding with any specific questions about the files.>\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"list_files\",\n",
      "    \"args\": {}\n",
      "}\n",
      "```\n",
      "Action result: {'result': ['.DS_Store', 'environment.yml', 'gemini_test.ipynb', 'gemini_prompting.ipynb', 'litellm_uuid.txt', 'ProgrammaticPrompting1.ipynb', '.gitignore', 'Practicing Programmatic Prompting.ipynb', '.env', '.gitattributes', '.ipynb_checkpoints', 'documents', '.git', 'first_agent.ipynb']}\n",
      "Agent thinking...\n",
      "Agent response: <Now that I have a list of files and directories in the current folder, I can check the available files. If the user has further questions regarding specific files or requests specific content information, I can proceed with reading that file. Since the user just inquired about what files are present, I've now gathered that information.>\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"terminate\",\n",
      "    \"args\": {\n",
      "        \"message\": \"The folder contains the following files and directories: .DS_Store, environment.yml, gemini_test.ipynb, gemini_prompting.ipynb, litellm_uuid.txt, ProgrammaticPrompting1.ipynb, .gitignore, Practicing Programmatic Prompting.ipynb, .env, .gitattributes, .ipynb_checkpoints, documents, .git, first_agent.ipynb.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "The folder contains the following files and directories: .DS_Store, environment.yml, gemini_test.ipynb, gemini_prompting.ipynb, litellm_uuid.txt, ProgrammaticPrompting1.ipynb, .gitignore, Practicing Programmatic Prompting.ipynb, .env, .gitattributes, .ipynb_checkpoints, documents, .git, first_agent.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# Initialize agent parameters\n",
    "iterations = 0\n",
    "max_iterations = 10\n",
    "\n",
    "user_task = input(\"What would you like me to do? \")\n",
    "\n",
    "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
    "\n",
    "# The Agent Loop\n",
    "while iterations < max_iterations:\n",
    "    # 1. Construct prompt: Combine agent rules with memory\n",
    "    prompt = agent_rules + memory\n",
    "\n",
    "    # 2. Generate response from LLM\n",
    "    print(\"Agent thinking...\")\n",
    "    response = generate_response(prompt)\n",
    "    print(f\"Agent response: {response}\")\n",
    "\n",
    "    # 3. Parse response to determine action\n",
    "    action = parse_action(response)\n",
    "    result = \"Action executed\"\n",
    "\n",
    "    if action[\"tool_name\"] == \"list_files\":\n",
    "        result = {\"result\": list_files()}\n",
    "    elif action[\"tool_name\"] == \"read_file\":\n",
    "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
    "    elif action[\"tool_name\"] == \"error\":\n",
    "        result = {\"error\": action[\"args\"][\"message\"]}\n",
    "    elif action[\"tool_name\"] == \"terminate\":\n",
    "        print(action[\"args\"][\"message\"])\n",
    "        break\n",
    "    else:\n",
    "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
    "\n",
    "    print(f\"Action result: {result}\")\n",
    "\n",
    "    # 5. Update memory with response and results\n",
    "    memory.extend([\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
    "    ])\n",
    "\n",
    "    # 6. Check termination condition\n",
    "    if action[\"tool_name\"] == \"terminate\":\n",
    "        break\n",
    "\n",
    "    iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f614ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_doc = '/Users/mahdihanifi/Documents/GitHub/AI-Agents-and-Agentic-AI-with-Pytho-and-Generative-AI/documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e503b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: list_files with args {}\n",
      "Result: {'result': ['8k_Amazon.pdf', '.DS_Store', 'CAT.png', 'sample_sales.xlsx', '8k_apple_2.pdf', '8k_Apple_1.pdf', 'Zara_Sales_Analysis.csv']}\n",
      "Response: Here are the file suffixes in the directory:\n",
      "\n",
      "1. `.pdf` for the PDF files\n",
      "2. `.DS_Store` which is a system file on macOS\n",
      "3. `.png` for the image file\n",
      "4. `.xlsx` for the Excel file\n",
      "5. `.csv` for the CSV file\n",
      "\n",
      "If you need more information about any of these files, please let me know!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "from litellm import completion\n",
    "\n",
    "def list_files() -> List[str]:\n",
    "    \"\"\"List files in the current directory.\"\"\"\n",
    "    return os.listdir(path_to_doc)\n",
    "\n",
    "def read_file(file_name: str) -> str:\n",
    "    \"\"\"Read a file's contents.\"\"\"\n",
    "    try:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: {file_name} not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def terminate(message: str) -> None:\n",
    "    \"\"\"Terminate the agent loop and provide a summary message.\"\"\"\n",
    "    print(f\"Termination message: {message}\")\n",
    "\n",
    "tool_functions = {\n",
    "    \"list_files\": list_files,\n",
    "    \"read_file\": read_file,\n",
    "    \"terminate\": terminate\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"list_files\",\n",
    "            \"description\": \"Returns a list of files in the directory.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_file\",\n",
    "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"file_name\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"terminate\",\n",
    "            \"description\": \"Terminates the conversation. No further actions or interactions are possible after this. Prints the provided message for the user.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"message\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"message\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are an AI agent that can perform tasks by using available tools. \n",
    "\n",
    "If a user asks about files, documents, or content, first list the files before reading them.\n",
    "\n",
    "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
    "\"\"\"\n",
    "}]\n",
    "\n",
    "# Initialize agent parameters\n",
    "iterations = 0\n",
    "max_iterations = 10\n",
    "\n",
    "user_task = input(\"What would you like me to do? \")\n",
    "\n",
    "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
    "\n",
    "# The Agent Loop\n",
    "while iterations < max_iterations:\n",
    "\n",
    "    messages = agent_rules + memory\n",
    "\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool = response.choices[0].message.tool_calls[0]\n",
    "        tool_name = tool.function.name\n",
    "        tool_args = json.loads(tool.function.arguments)\n",
    "\n",
    "        action = {\n",
    "            \"tool_name\": tool_name,\n",
    "            \"args\": tool_args\n",
    "        }\n",
    "\n",
    "        if tool_name == \"terminate\":\n",
    "            print(f\"Termination message: {tool_args['message']}\")\n",
    "            break\n",
    "        elif tool_name in tool_functions:\n",
    "            try:\n",
    "                result = {\"result\": tool_functions[tool_name](**tool_args)}\n",
    "            except Exception as e:\n",
    "                result = {\"error\":f\"Error executing {tool_name}: {str(e)}\"}\n",
    "        else:\n",
    "            result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
    "\n",
    "        print(f\"Executing: {tool_name} with args {tool_args}\")\n",
    "        print(f\"Result: {result}\")\n",
    "        memory.extend([\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(action)},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(result)}\n",
    "        ])\n",
    "    else:\n",
    "        result = response.choices[0].message.content\n",
    "        print(f\"Response: {result}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36e92e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_B2G336toagOSDMMXFUDEgCCK', type='function')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66797006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
