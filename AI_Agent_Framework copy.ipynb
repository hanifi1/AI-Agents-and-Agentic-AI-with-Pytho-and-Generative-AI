{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2013306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Automatically looks for \".env\"\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import json\n",
    "import time\n",
    "import traceback\n",
    "from litellm import completion\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Callable, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87446d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Prompt:\n",
    "    messages: List[Dict] = field(default_factory=list)\n",
    "    tools: List[Dict] = field(default_factory=list)\n",
    "    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue\n",
    "\n",
    "\n",
    "def generate_response(prompt: Prompt) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "\n",
    "    messages = prompt.messages\n",
    "    tools = prompt.tools\n",
    "\n",
    "    result = None\n",
    "\n",
    "    if not tools:\n",
    "        response = completion(\n",
    "            model=\"openai/gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "    else:\n",
    "        response = completion(\n",
    "            model=\"openai/gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            tool = response.choices[0].message.tool_calls[0]\n",
    "            result = {\n",
    "                \"tool\": tool.function.name,\n",
    "                \"args\": json.loads(tool.function.arguments),\n",
    "            }\n",
    "            result = json.dumps(result)\n",
    "        else:\n",
    "            result = response.choices[0].message.content\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbdea2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Goal:\n",
    "    priority: int\n",
    "    name: str\n",
    "    description: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d182f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = [\n",
    "    Goal(\n",
    "        priority=1,\n",
    "        name=\"Business Analyst AI Agent\",\n",
    "        description=\"Act as a Business Analyst AI agent.\"\n",
    "    ),\n",
    "    Goal(\n",
    "        priority=2,\n",
    "        name=\"File Analysis\",\n",
    "        description=\"Read and analyze Excel (.xlsx), CSV, and Word (.doc/.docx) files.\"\n",
    "    ),\n",
    "    Goal(\n",
    "        priority=3,\n",
    "        name=\"Answer Questions\",\n",
    "        description=\"Answer user questions about the data in clear, professional business language.\"\n",
    "    ),\n",
    "    Goal(\n",
    "        priority=4,\n",
    "        name=\"Analysis Features\",\n",
    "        description=\"Provide summaries, comparisons, trend analysis, and highlight anomalies.\"\n",
    "    ),\n",
    "    Goal(\n",
    "        priority=5,\n",
    "        name=\"Reference Sources\",\n",
    "        description=\"Always reference the file(s) and section(s) used in the answer.\"\n",
    "    ),\n",
    "    Goal(\n",
    "        priority=6,\n",
    "        name=\"Clarifying Questions\",\n",
    "        description=\"Ask clarifying questions if the data or request is unclear.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e121a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Action:\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 function: Callable,\n",
    "                 description: str,\n",
    "                 parameters: Dict,\n",
    "                 terminal: bool = False):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.description = description\n",
    "        self.terminal = terminal\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def execute(self, **args) -> Any:\n",
    "        \"\"\"Execute the action's function\"\"\"\n",
    "        return self.function(**args)\n",
    "\n",
    "\n",
    "class ActionRegistry:\n",
    "    def __init__(self):\n",
    "        self.actions = {}\n",
    "\n",
    "    def register(self, action: Action):\n",
    "        self.actions[action.name] = action\n",
    "\n",
    "    def get_action(self, name: str) -> [Action, None]:\n",
    "        return self.actions.get(name, None)\n",
    "\n",
    "    def get_actions(self) -> List[Action]:\n",
    "        \"\"\"Get all registered actions\"\"\"\n",
    "        return list(self.actions.values())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a10e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Lists all CSV and Excel files in the specified directory.\n",
    "    \"\"\"\n",
    "    path = os.path.join(path)\n",
    "    try:\n",
    "        files = os.listdir(path)\n",
    "        # Filter for CSV and Excel files\n",
    "        data_files = [f for f in files if f.endswith('.csv') or f.endswith('.xlsx')]\n",
    "        return data_files\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Directory not found at {path}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def read_data(path: str, file_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV or Excel file from a given file path into a pandas DataFrame.\n",
    "    Handles errors for non-existent files or unsupported formats.\n",
    "    \"\"\"\n",
    "    file = os.path.join(path, file_name)\n",
    "    try:\n",
    "        # Check the file extension to use the correct pandas function\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(file)\n",
    "            return df.to_dict(orient=\"records\")\n",
    "        elif file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file)\n",
    "            return df.to_dict(orient=\"records\")\n",
    "        else:\n",
    "            # If the format isn't supported, we return an error message\n",
    "            return \"Error: Unsupported file format. Please use .csv or .xlsx.\"\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, we return an error message\n",
    "        return f\"Error: File not found at {file}\"\n",
    "    except Exception as e:\n",
    "        # Catch any other potential errors during file reading\n",
    "        return f\"An error occurred: {e}\"\n",
    "    \n",
    "\n",
    "def analyze_data(df: pd.DataFrame, command: str):\n",
    "    \"\"\"\n",
    "    Dynamically executes a pandas command on a DataFrame.\n",
    "    Example command: \"df['Sale_Amount'].mean()\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The eval() function runs the code in the command string\n",
    "        result = eval(command)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # If the command is invalid, return an error message\n",
    "        return f\"Error executing command: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd4c7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and populate the action registry\n",
    "registry = ActionRegistry()\n",
    "\n",
    "registry.register(Action(\n",
    "    name=\"list_files\",\n",
    "    function=list_files,\n",
    "    description=\"Lists all CSV and Excel files in the specified directory.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"path\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Path to the directory containing files\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"path\"]\n",
    "    },\n",
    "    terminal=False\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "registry.register(Action(\n",
    "    name=\"read_data\",\n",
    "    function=read_data,\n",
    "    description=\"Read a CSV or Excel file into a pandas DataFrame.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"path\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Path to the directory containing files\",\n",
    "            },\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the file to read\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"path\", \"file_name\"]\n",
    "    },\n",
    "    terminal=False\n",
    "))  \n",
    "\n",
    "registry.register(Action(\n",
    "    name=\"analyze_data\",\n",
    "    function=analyze_data,\n",
    "    description=\"Analyze the data using a pandas command.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"df\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"DataFrame data as a list of records\"\n",
    "            },\n",
    "            \"command\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Pandas command to execute on the DataFrame\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"df\", \"command\"]\n",
    "    },\n",
    "    terminal=False\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe275ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.items = []  # Basic conversation histor\n",
    "\n",
    "    def add_memory(self, memory: dict):\n",
    "        \"\"\"Add memory to working memory\"\"\"\n",
    "        self.items.append(memory)\n",
    "\n",
    "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
    "        \"\"\"Get formatted conversation history for prompt\"\"\"\n",
    "        return self.items[:limit]\n",
    "\n",
    "    def copy_without_system_memories(self):\n",
    "        \"\"\"Return a copy of the memory without system memories\"\"\"\n",
    "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
    "        memory = Memory()\n",
    "        memory.items = filtered_items\n",
    "        return memory\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def execute_action(self, action: Action, args: dict) -> dict:\n",
    "        \"\"\"Execute an action and return the result.\"\"\"\n",
    "        try:\n",
    "            result = action.execute(**args)\n",
    "            return self.format_result(result)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"tool_executed\": False,\n",
    "                \"error\": str(e),\n",
    "                \"traceback\": traceback.format_exc()\n",
    "            }\n",
    "\n",
    "    def format_result(self, result: Any) -> dict:\n",
    "        \"\"\"Format the result with metadata.\"\"\"\n",
    "        return {\n",
    "            \"tool_executed\": True,\n",
    "            \"result\": result,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AgentLanguage:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def construct_prompt(self,\n",
    "                         actions: List[Action],\n",
    "                         environment: Environment,\n",
    "                         goals: List[Goal],\n",
    "                         memory: Memory) -> Prompt:\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "\n",
    "\n",
    "    def parse_response(self, response: str) -> dict:\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "\n",
    "\n",
    "\n",
    "class AgentFunctionCallingActionLanguage(AgentLanguage):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def format_goals(self, goals: List[Goal]) -> List:\n",
    "        # Map all goals to a single string that concatenates their description\n",
    "        # and combine into a single message of type system\n",
    "        sep = \"\\n-------------------\\n\"\n",
    "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": goal_instructions}\n",
    "        ]\n",
    "\n",
    "    def format_memory(self, memory: Memory) -> List:\n",
    "        \"\"\"Generate response from language model\"\"\"\n",
    "        # Map all environment results to a role:user messages\n",
    "        # Map all assistant messages to a role:assistant messages\n",
    "        # Map all user messages to a role:user messages\n",
    "        items = memory.get_memories()\n",
    "        mapped_items = []\n",
    "        for item in items:\n",
    "\n",
    "            content = item.get(\"content\", None)\n",
    "            if not content:\n",
    "                content = json.dumps(item, indent=4)\n",
    "\n",
    "            if item[\"type\"] == \"assistant\":\n",
    "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
    "            elif item[\"type\"] == \"environment\":\n",
    "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
    "            else:\n",
    "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        return mapped_items\n",
    "\n",
    "    def format_actions(self, actions: List[Action]) -> [List,List]:\n",
    "        \"\"\"Generate response from language model\"\"\"\n",
    "\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": action.name,\n",
    "                    # Include up to 1024 characters of the description\n",
    "                    \"description\": action.description[:1024],\n",
    "                    \"parameters\": action.parameters,\n",
    "                },\n",
    "            } for action in actions\n",
    "        ]\n",
    "\n",
    "        return tools\n",
    "\n",
    "    def construct_prompt(self,\n",
    "                         actions: List[Action],\n",
    "                         environment: Environment,\n",
    "                         goals: List[Goal],\n",
    "                         memory: Memory) -> Prompt:\n",
    "\n",
    "        prompt = []\n",
    "        prompt += self.format_goals(goals)\n",
    "        prompt += self.format_memory(memory)\n",
    "\n",
    "        tools = self.format_actions(actions)\n",
    "\n",
    "        return Prompt(messages=prompt, tools=tools)\n",
    "\n",
    "    def adapt_prompt_after_parsing_error(self,\n",
    "                                         prompt: Prompt,\n",
    "                                         response: str,\n",
    "                                         traceback: str,\n",
    "                                         error: Any,\n",
    "                                         retries_left: int) -> Prompt:\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def parse_response(self, response: str) -> dict:\n",
    "        \"\"\"Parse LLM response into structured format by extracting the ```json block\"\"\"\n",
    "\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"tool\": \"terminate\",\n",
    "                \"args\": {\"message\":response}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self,\n",
    "                 goals: List[Goal],\n",
    "                 agent_language: AgentLanguage,\n",
    "                 action_registry: ActionRegistry,\n",
    "                 generate_response: Callable[[Prompt], str],\n",
    "                 environment: Environment):\n",
    "        \"\"\"\n",
    "        Initialize an agent with its core GAME components\n",
    "        \"\"\"\n",
    "        self.goals = goals\n",
    "        self.generate_response = generate_response\n",
    "        self.agent_language = agent_language\n",
    "        self.actions = action_registry\n",
    "        self.environment = environment\n",
    "\n",
    "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
    "        \"\"\"Build prompt with memory context\"\"\"\n",
    "        return self.agent_language.construct_prompt(\n",
    "            actions=actions.get_actions(),\n",
    "            environment=self.environment,\n",
    "            goals=goals,\n",
    "            memory=memory\n",
    "        )\n",
    "\n",
    "    def get_action(self, response):\n",
    "        invocation = self.agent_language.parse_response(response)\n",
    "        action = self.actions.get_action(invocation[\"tool\"])\n",
    "        return action, invocation\n",
    "\n",
    "    def should_terminate(self, response: str) -> bool:\n",
    "        action_def, _ = self.get_action(response)\n",
    "        return action_def.terminal\n",
    "\n",
    "    def set_current_task(self, memory: Memory, task: str):\n",
    "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
    "\n",
    "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
    "        \"\"\"\n",
    "        Update memory with the agent's decision and the environment's response.\n",
    "        \"\"\"\n",
    "        new_memories = [\n",
    "            {\"type\": \"assistant\", \"content\": response},\n",
    "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
    "        ]\n",
    "        for m in new_memories:\n",
    "            memory.add_memory(m)\n",
    "\n",
    "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
    "        response = self.generate_response(full_prompt)\n",
    "        return response\n",
    "\n",
    "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
    "        \"\"\"\n",
    "        Execute the GAME loop for this agent with a maximum iteration limit.\n",
    "        \"\"\"\n",
    "        memory = memory or Memory()\n",
    "        self.set_current_task(memory, user_input)\n",
    "\n",
    "        for _ in range(max_iterations):\n",
    "            # Construct a prompt that includes the Goals, Actions, and the current Memory\n",
    "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
    "\n",
    "            print(\"Agent thinking...\")\n",
    "            # Generate a response from the agent\n",
    "            response = self.prompt_llm_for_action(prompt)\n",
    "            print(f\"Agent Decision: {response}\")\n",
    "\n",
    "            # Determine which action the agent wants to execute\n",
    "            action, invocation = self.get_action(response)\n",
    "\n",
    "            # Execute the action in the environment\n",
    "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
    "            print(f\"Action Result: {result}\")\n",
    "\n",
    "            # Update the agent's memory with information about what happened\n",
    "            self.update_memory(memory, response, result)\n",
    "\n",
    "            # Check if the agent has decided to terminate\n",
    "            if self.should_terminate(response):\n",
    "                break\n",
    "\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ef6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "file_explorer_agent = Agent(\n",
    "    goals=goals,\n",
    "    agent_language=agent_language,\n",
    "    action_registry=action_registry,\n",
    "    generate_response=generate_response,\n",
    "    environment=environment\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "user_input = input(\"What would you like me to do? \")\n",
    "final_memory = file_explorer_agent.run(user_input, max_iterations=10)\n",
    "\n",
    "# Print the final conversation if desired\n",
    "for item in final_memory.get_memories():\n",
    "    print(f\"\\n{item['type'].upper()}: {item['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b9cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
